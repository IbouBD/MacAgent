{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cbcb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/ibrahimbaldediallo/Documents/Code/Jarvis_project/vocab/instruction.txt\"\n",
    "model_path = \"/Users/ibrahimbaldediallo/Documents/Code/Jarvis_project/TD/actor3.pth\"\n",
    "id_to_action_path = \"/Users/ibrahimbaldediallo/Documents/Code/Jarvis_project/notebook/id_to_action.json\"\n",
    "action_to_id_path = \"/Users/ibrahimbaldediallo/Documents/Code/Jarvis_project/notebook/action_to_id.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6486c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(id_to_action_path) as f:\n",
    "    id_to_action_raw = json.load(f)\n",
    "\n",
    "id_to_action = {int(k): v for k, v in id_to_action_raw.items()}\n",
    "\n",
    "with open(action_to_id_path) as f:\n",
    "    action_to_id_raw = json.load(f)\n",
    "\n",
    "action_to_id = {k: int(v) for k, v in action_to_id_raw.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d5d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(action_to_id)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc172e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cf9651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=50):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38856332",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f886b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "with open(path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.lower()\n",
    "        l.append(line.strip())\n",
    "\n",
    "for data in l:\n",
    "    split_data = data.split(\";\")\n",
    "    x = split_data[0]\n",
    "    y = split_data[1]\n",
    "    try:\n",
    "        y = y.replace(\"system preferences\", \"system_preferences\")\n",
    "        y = y.replace(\" \", \"\")\n",
    "        y = f\"cmd+space {y} enter\"\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    X.append(x)\n",
    "    Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c53529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0])\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_idx = []\n",
    "Y_idx_sentence = []\n",
    "for s in Y:\n",
    "    s = s.split()\n",
    "    s = [action_to_id[word] for word in s]\n",
    "    Y_idx.append(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef85ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "data = []\n",
    "PAD = action_to_id.get(\"<PAD>\", 0)\n",
    "BOS = action_to_id.get(\"<BOS>\", 1)\n",
    "EOS = action_to_id.get(\"<EOS>\", 2)\n",
    "UNK = action_to_id.get(\"<UNK>\", 3)\n",
    "\n",
    "decoder_inputs = []\n",
    "decoder_targets = []\n",
    "encoder_inputs = []\n",
    "\n",
    "# Construction brute des séquences\n",
    "for x, y in zip(X, Y_idx):\n",
    "    input_ids = encoder.encode(x, convert_to_tensor=True).to(device)\n",
    "    decoder_input = [BOS] + y\n",
    "    decoder_target = y + [EOS]\n",
    "\n",
    "    encoder_inputs.append(input_ids)\n",
    "    decoder_inputs.append(torch.tensor(decoder_input, dtype=torch.long))\n",
    "    decoder_targets.append(torch.tensor(decoder_target, dtype=torch.long))\n",
    "\n",
    "# Trouver la longueur max\n",
    "max_len = max(max(len(seq) for seq in decoder_inputs),\n",
    "              max(len(seq) for seq in decoder_targets))\n",
    "\n",
    "# Padding des séquences\n",
    "decoder_inputs_padded = pad_sequence(decoder_inputs, batch_first=True, padding_value=PAD)\n",
    "decoder_targets_padded = pad_sequence(decoder_targets, batch_first=True, padding_value=PAD)\n",
    "\n",
    "# Combine avec les entrées encodeur\n",
    "for i in range(len(X)):\n",
    "    data.append((encoder_inputs[i],\n",
    "                 (decoder_inputs_padded[i], decoder_targets_padded[i])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data[0]\n",
    "b = data[1]\n",
    "print(a[1][0].shape)\n",
    "print(b[1][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    encoder_batch = torch.stack([item[0] for item in batch])\n",
    "    decoder_input_batch = torch.stack([item[1][0] for item in batch])\n",
    "    decoder_target_batch = torch.stack([item[1][1] for item in batch])\n",
    "    return {\n",
    "        \"encoder_input\": encoder_batch,\n",
    "        \"decoder_input\": decoder_input_batch,\n",
    "        \"decoder_target\": decoder_target_batch\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308868ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "dataloader = DataLoader(\n",
    "    data,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda batch: collate_fn(batch)\n",
    ")\n",
    "\n",
    "# Exemple d'une itération\n",
    "for batch in dataloader:\n",
    "    encoder_input = batch[\"encoder_input\"]        # (B, D)\n",
    "    decoder_input = batch[\"decoder_input\"]        # (B, T)\n",
    "    decoder_target = batch[\"decoder_target\"]      # (B, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cd6bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(sequences, id_to_action, stop_token=\"<EOS>\"):\n",
    "    decoded_sequences = []\n",
    "    for sequence in sequences:\n",
    "        decoded = []\n",
    "        for idx in sequence:\n",
    "            token = id_to_action.get(idx, \"<UNK>\")\n",
    "            if token == stop_token:\n",
    "                break\n",
    "            decoded.append(token)\n",
    "        decoded_sequences.append(decoded)\n",
    "    return decoded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422987ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_targets = decode(batch[\"decoder_target\"], id_to_action)\n",
    "print(batch[\"decoder_target\"].tolist())\n",
    "print(decoded_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b76d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in batch[\"decoder_input\"][0].tolist():\n",
    "    print(idx, id_to_action.get(idx, \"<UNK>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e6a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc348db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualFFN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_blocks=2):\n",
    "        super(ResidualFFN, self).__init__()\n",
    "        \n",
    "        # Projection initiale\n",
    "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # Blocs résiduels\n",
    "        self.res_blocks = nn.ModuleList([\n",
    "            ResidualBlock(hidden_dim) for _ in range(num_blocks)\n",
    "        ])\n",
    "        \n",
    "        # Projection finale\n",
    "        self.output_proj = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        # Appliquer les blocs résiduels\n",
    "        for block in self.res_blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        return self.output_proj(x)\n",
    "        \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim, dropout=0.3):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim * 4, dim)\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.norm(x + self.layers(x))\n",
    "    \n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim, max_len=512):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, dim, 2).float() * (-math.log(10000.0) / dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(1)  # (max_len, 1, dim)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_len, batch_size, dim)\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return x\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, encoder, dim, hidden, vocab_size, max_len=128):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder  # pretrained SentenceTransformer\n",
    "        self.rffn = ResidualFFN(384, hidden, dim)\n",
    "        self.embedding = nn.Embedding(vocab_size, dim)\n",
    "        self.pos_encoding = PositionalEncoding(dim, max_len=max_len)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=dim, nhead=16, dim_feedforward=hidden, dropout=0.3)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=2)  # Réduction de 6 à 2 couches\n",
    "        self.final_projection = nn.Linear(dim, vocab_size)\n",
    "        self.max_len = max_len\n",
    "        self.dim = dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    def forward(self, x_texts, tgt):\n",
    "        \"\"\"\n",
    "        x_texts: list of strings, len = batch_size\n",
    "        tgt: tensor of shape (batch_size, seq_len)\n",
    "        \"\"\"\n",
    "        batch_size = len(x_texts)\n",
    "        \n",
    "        # Encode input texts\n",
    "        with torch.no_grad():\n",
    "            x = self.encoder.encode(x_texts, convert_to_tensor=True)  # shape: (batch_size, 384)\n",
    "        x = self.rffn(x)  # shape: (batch_size, dim)\n",
    "       \n",
    "\n",
    "        # Prepare target sequence\n",
    "        tgt = tgt.to(device)\n",
    "        tgt = self.embedding(tgt)  # (batch_size, seq_len, dim)\n",
    "        tgt = tgt.permute(1, 0, 2)  # (seq_len, batch_size, dim)\n",
    "        tgt = self.pos_encoding(tgt)  # add positional encoding\n",
    "\n",
    "        # Create mask for autoregressive decoding\n",
    "        seq_len = tgt.size(0)\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(seq_len).to(tgt.device)\n",
    "        x = x.unsqueeze(0).repeat(seq_len, 1, 1)  # (seq_len, batch_size, dim)\n",
    "        # Decode\n",
    "        z = self.transformer_decoder(tgt, x, tgt_mask=tgt_mask)  # (seq_len, batch_size, dim)\n",
    "        z = self.final_projection(z)  # (seq_len, batch_size, vocab_size)\n",
    "        z = z.permute(1, 0, 2)  # (batch_size, seq_len, vocab_size)\n",
    "\n",
    "        return z\n",
    "    \n",
    "    def forward_training(self, x, tgt):\n",
    "        \"\"\"\n",
    "        x: encoder output (batch_size, dim)\n",
    "        tgt: tensor of shape (batch_size, seq_len)\n",
    "        \"\"\"\n",
    "\n",
    "        # Projette x dans le bon espace si nécessaire\n",
    "        x = self.rffn(x)  # (batch_size, dim)\n",
    "\n",
    "        # Embedding + Positional encoding\n",
    "        tgt = self.embedding(tgt)  # (batch_size, seq_len, dim)\n",
    "        tgt = tgt.permute(1, 0, 2)  # (seq_len, batch_size, dim)\n",
    "        tgt = self.pos_encoding(tgt)\n",
    "\n",
    "        # Memory (encoder output) doit être (seq_len_enc, batch_size, dim)\n",
    "        # Ici on suppose x est global, donc on le répète\n",
    "        x = x.unsqueeze(0)  # (1, batch_size, dim)\n",
    "\n",
    "        # Masque auto-régressif pour le décodeur\n",
    "        seq_len = tgt.size(0)\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(seq_len).to(tgt.device)\n",
    "\n",
    "        # Transformer decoder\n",
    "        z = self.transformer_decoder(tgt, x, tgt_mask=tgt_mask)  # (seq_len, batch_size, dim)\n",
    "        z = self.final_projection(z)  # (seq_len, batch_size, vocab_size)\n",
    "        z = z.permute(1, 0, 2)  # (batch_size, seq_len, vocab_size)\n",
    "\n",
    "        return z\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def generate(self, x_text:list[str], max_len=32, start_token_id=1, end_token_id=2):\n",
    "        \"\"\"\n",
    "        x_text : liste de string\n",
    "        Retourne une liste de listes contenant les ID générés\n",
    "        \"\"\"\n",
    "        # Encode input texts\n",
    "        with torch.no_grad():\n",
    "            x = self.encoder.encode(x_text, convert_to_tensor=True)\n",
    "        # Encoder: passe par rffn si nécessaire\n",
    "        x = self.rffn(x)  # (batch_size, dim)\n",
    "        memory = x.unsqueeze(0)  # (1, batch_size, dim)\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        device = x.device\n",
    "\n",
    "        # Initialiser avec <BOS>\n",
    "        generated = torch.full((batch_size, 1), start_token_id, dtype=torch.long, device=device)\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            # Embed + position\n",
    "            tgt_embed = self.embedding(generated)  # (batch_size, seq_len, dim)\n",
    "            tgt_embed = tgt_embed.permute(1, 0, 2)  # (seq_len, batch_size, dim)\n",
    "            tgt_embed = self.pos_encoding(tgt_embed)\n",
    "\n",
    "            # Masque causal\n",
    "            seq_len = generated.size(1)\n",
    "            tgt_mask = nn.Transformer.generate_square_subsequent_mask(seq_len).to(device)\n",
    "\n",
    "            # Decode\n",
    "            output = self.transformer_decoder(tgt_embed, memory, tgt_mask=tgt_mask)\n",
    "            logits = self.final_projection(output)  # (seq_len, batch_size, vocab_size)\n",
    "            next_token_logits = logits[-1, :, :]  # dernier pas de temps → (batch_size, vocab_size)\n",
    "\n",
    "            # Greedy : choisir l'indice du max\n",
    "            next_token = torch.argmax(next_token_logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "            # Ajouter à la séquence\n",
    "            generated = torch.cat([generated, next_token], dim=1)\n",
    "\n",
    "            # Option d'arrêt : si tous les batchs ont généré <EOS>\n",
    "            if (next_token == end_token_id).all():\n",
    "                break\n",
    "\n",
    "        return generated  # (batch_size, seq_len_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8783990",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim, hidden, = 512, 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027da676",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = Actor(encoder, dim, hidden, vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f817e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c152ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch[\"encoder_input\"].shape)\n",
    "print(batch[\"decoder_target\"][0])\n",
    "print(batch[\"decoder_target\"][:, 1:][0])\n",
    "print(batch[\"decoder_input\"][0])\n",
    "print(batch[\"decoder_input\"][:, :-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2ba141",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = actor.forward_training(batch[\"encoder_input\"].to(device), batch[\"decoder_target\"].to(device))\n",
    "print(p)\n",
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed0b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataset, test_dataset, epochs, learning_rate):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)     \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    epoch_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in train_dataset:\n",
    "            encoder_input = batch[\"encoder_input\"].to(device)\n",
    "            decoder_input = batch[\"decoder_input\"].to(device)\n",
    "            decoder_target = batch[\"decoder_target\"].to(device)\n",
    "            \n",
    "            # tgt_input : tout sauf le dernier token\n",
    "            decoder_input = decoder_input\n",
    "            # tgt_output : tout sauf le premier token (ce qu’on doit prédire)\n",
    "            decoder_target = decoder_target\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model.forward_training(encoder_input, decoder_input)  # shape: (batch_size, seq_len, vocab_size)\n",
    "            \n",
    "            loss = criterion(output.reshape(-1, vocab_size), decoder_target.reshape(-1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_dataset)\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "        #val_loss = evaluate_model(model, test_dataset)\n",
    "        scheduler.step()\n",
    "\n",
    "        #print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(actor, dataloader, None, epochs=1, learning_rate=1e-6)  # best lr for now is 1e-4, 4e-5, 2e-5 avec 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73a97fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(actor.state_dict(), 'actor4.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
